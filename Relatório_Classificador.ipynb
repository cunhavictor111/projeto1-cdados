{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Victor de Almeida Cunha\n",
    "\n",
    "Nome: André Samara Levorin\n",
    "\n",
    "Nome: Caio Cavalcante Bueno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "c:\\Users\\Victor Cunha\\Desktop\\Atividades\\C-Dados\\CDADOS - DP\\projeto1-cdados\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados manualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Não cheguei a completar a leitura do livro, te...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Péssimo. Qualidade horrível do papel, tamanho ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fiz a compra do produto e chegou tudo certo co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vetusto, tanto quanto o próprio autor, comprar...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Se soubesse não teria comprado. É bom pra apre...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Mensagem  Target\n",
       "0  Não cheguei a completar a leitura do livro, te...       2\n",
       "1  Péssimo. Qualidade horrível do papel, tamanho ...       2\n",
       "2  Fiz a compra do produto e chegou tudo certo co...       0\n",
       "3  Vetusto, tanto quanto o próprio autor, comprar...       2\n",
       "4  Se soubesse não teria comprado. É bom pra apre...       2"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel('dados_treino_CLASSIFICADO.xlsx')\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Livro ruim, comparado com seu antecessor! A au...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O Livro é um resumo do canal Me Poupe! O Conte...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Desnecessário comentar. Não percam tempo. Níve...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Essa encomenda não veio pelos correios e chego...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Assim como todos os livro da Série, não curti....</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Mensagem  Target\n",
       "0  Livro ruim, comparado com seu antecessor! A au...       2\n",
       "1  O Livro é um resumo do canal Me Poupe! O Conte...       2\n",
       "2  Desnecessário comentar. Não percam tempo. Níve...       2\n",
       "3  Essa encomenda não veio pelos correios e chego...       0\n",
       "4  Assim como todos os livro da Série, não curti....       2"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel('dados_teste_CLASSIFICADO.xlsx')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O intuito do classificador que montaremos é de usar conceitos e análises probabilísticas para fazer com que uma avaliação automática chegue o mais perto possível da avaliação manual de cada mensagem do Dataframe, utilizando as palavras como referência principal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Separando as probabilidades do Dataframe de treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para início, vamos importar algumas funções de limpeza para facilitar o entendimento de cada avaliação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    punctuation = '[´\"!-.:?;$'']' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed\n",
    "\n",
    "def limpaStopwords(phrase):\n",
    "\n",
    "    # Importação de uma lista de stopwords para minimizar palavras desnecessárias.\n",
    "\n",
    "    stop_words = ['e', 'a', 'o','de','da', 'em','do', 'as', 'dos', 'das', 'no', 'na', 'quem', 'ao', 'que', 'sua','seu', 'por', 'uma', \n",
    "    'um', 'os', 'se','sobre', 'mas','são','entre', 'assim', 'esse', 'essa', 'diz', 'deve', 'anos', 'dia', 't', 'mi', 'nesta','neste','nesse','nessa', 'aos', 'com', 'já', 'para', 'mais','após','no','pelo', 'antes','depois', 'nos',\n",
    "    'é', 'pela', 'desta','se','sobre', 'mas','são', 'que']\n",
    "\n",
    "    # Dividiremos a review em cada palavra e removeremos todas as que são stopwords.\n",
    "    \n",
    "    frase = phrase.split()\n",
    "    sem_stop = ''\n",
    "    for word in frase:\n",
    "        if word in stop_words:\n",
    "            frase.remove(word)\n",
    "        else:\n",
    "            sem_stop += word + ' '\n",
    "    return sem_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O próximo passo é separar o nosso Dataframe de treino em 3 diferentes (um para cada tipo de avaliação), além de um apenas com as mensagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Não cheguei a completar a leitura do livro, te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Péssimo. Qualidade horrível do papel, tamanho ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fiz a compra do produto e chegou tudo certo co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vetusto, tanto quanto o próprio autor, comprar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Se soubesse não teria comprado. É bom pra apre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Mensagem\n",
       "0  Não cheguei a completar a leitura do livro, te...\n",
       "1  Péssimo. Qualidade horrível do papel, tamanho ...\n",
       "2  Fiz a compra do produto e chegou tudo certo co...\n",
       "3  Vetusto, tanto quanto o próprio autor, comprar...\n",
       "4  Se soubesse não teria comprado. É bom pra apre..."
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe com as avaliações positivas\n",
    "\n",
    "train_pos = train.loc[train['Target'] == 1, ['Mensagem']]\n",
    "\n",
    "# Dataframe com as avaliações negativas\n",
    "\n",
    "train_neg = train.loc[train['Target'] == 2, ['Mensagem']]\n",
    "\n",
    "# Dataframe com as avaliações irrelevantes\n",
    "\n",
    "train_irr = train.loc[train['Target'] == 0, ['Mensagem']]\n",
    "\n",
    "# Dataframe apenas com as mensagens\n",
    "\n",
    "train_all = train.loc[:,['Mensagem']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, iremos fazer diferentes cálculos de probabilidade. De começo, iremos ver a chance de uma palavra aparecer em uma avaliação qualquer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeiro, criamos uma lista com todas as palavras do Dataframe original.\n",
    "\n",
    "all_words = []\n",
    "\n",
    "for review in train_all['Mensagem']:\n",
    "\n",
    "    # Limparemos cada uma das mensagens para que a identificação fique correta.\n",
    "\n",
    "    review = cleanup(review)\n",
    "    review = limpaStopwords(review)\n",
    "\n",
    "    # Agora, dividiremos em uma lista apenas com as palavras.\n",
    "\n",
    "    words_review = review.split()\n",
    "    for word in words_review:\n",
    "\n",
    "        # Adicionaremos à lista apenas palavras únicas, sem serem repetidas.\n",
    "\n",
    "        if word not in all_words:\n",
    "            all_words.append(word)\n",
    "\n",
    "# O mesmo processo será feito agora pra um dicionário, que terá a palavra como chave e a probabilidade dela aparecer\n",
    "# em uma mensagem como valor.\n",
    "\n",
    "word_probability_total = {}\n",
    "\n",
    "for word in all_words:\n",
    "    count_word = 0\n",
    "    for review in train_all['Mensagem']:\n",
    "        review = cleanup(review)\n",
    "        review = limpaStopwords(review)\n",
    "        words_review = review.split()\n",
    "        if word in words_review:\n",
    "            count_word += 1\n",
    "\n",
    "    # Aqui, estamos dividindo em quantas mensagens a palavra apareceu pelo total de mensagens, e adicionando o valor ao dicionário.\n",
    "\n",
    "    prob_appearance = count_word/len(train_all['Mensagem'])\n",
    "    word_probability_total[word] = prob_appearance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, repetiremos o mesmo processo, mas para encontrar qual é a chance de uma palavra em uma avaliação positiva aparecer em uma avaliação positiva qualquer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_positive = []\n",
    "\n",
    "for review in train_pos['Mensagem']:\n",
    "    review = cleanup(review)\n",
    "    review = limpaStopwords(review)\n",
    "    words_review = review.split()\n",
    "    for word in words_review:\n",
    "        if word not in all_words_positive:\n",
    "            all_words_positive.append(word)\n",
    "\n",
    "word_probability_positive = {}\n",
    "\n",
    "for word in all_words_positive:\n",
    "    count_word = 0\n",
    "    for review in train_pos['Mensagem']:\n",
    "        review = cleanup(review)\n",
    "        review = limpaStopwords(review)\n",
    "        words_review = review.split()\n",
    "        if word in words_review:\n",
    "            count_word += 1\n",
    "\n",
    "    # A diferença principal das repetições seguintes é que o total agora é de mensagens com o tipo de avaliação.\n",
    "    \n",
    "    prob_appearance = count_word/len(train_pos['Mensagem'])\n",
    "    word_probability_positive[word] = prob_appearance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E então, o processo é repetido para as avaliações negativas e irrelevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_negative = []\n",
    "\n",
    "for review in train_neg['Mensagem']:\n",
    "    review = cleanup(review)\n",
    "    review = limpaStopwords(review)\n",
    "    words_review = review.split()\n",
    "    for word in words_review:\n",
    "        if word not in all_words_negative:\n",
    "            all_words_negative.append(word)\n",
    "\n",
    "word_probability_negative = {}\n",
    "\n",
    "for word in all_words_negative:\n",
    "    count_word = 0\n",
    "    for review in train_neg['Mensagem']:\n",
    "        review = cleanup(review)\n",
    "        review = limpaStopwords(review)\n",
    "        words_review = review.split()\n",
    "        if word in words_review:\n",
    "            count_word += 1\n",
    "    prob_appearance = count_word/len(train_neg['Mensagem'])\n",
    "    word_probability_negative[word] = prob_appearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_irrelevant = []\n",
    "\n",
    "for review in train_irr['Mensagem']:\n",
    "    review = cleanup(review)\n",
    "    review = limpaStopwords(review)\n",
    "    words_review = review.split()\n",
    "    for word in words_review:\n",
    "        if word not in all_words_irrelevant:\n",
    "            all_words_irrelevant.append(word)\n",
    "\n",
    "word_probability_irrelevant = {}\n",
    "\n",
    "for word in all_words_irrelevant:\n",
    "    count_word = 0\n",
    "    for review in train_irr['Mensagem']:\n",
    "        review = cleanup(review)\n",
    "        review = limpaStopwords(review)\n",
    "        words_review = review.split()\n",
    "        if word in words_review:\n",
    "            count_word += 1\n",
    "    prob_appearance = count_word/len(train_irr['Mensagem'])\n",
    "    word_probability_irrelevant[word] = prob_appearance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, veremos a possibilidade de uma avaliação qualquer ser positiva, negativa ou irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.138\n",
      "0.652\n",
      "0.21\n"
     ]
    }
   ],
   "source": [
    "# O cálculo de probabilidade de cada tipo de avaliação\n",
    "# é feito por dividir quantas mensagens de cada tipo de avaliação existem\n",
    "# pelo total de mensagens.\n",
    "\n",
    "positive_review_probability = len(train_pos['Mensagem'])/len(train_all['Mensagem'])\n",
    "negative_review_probability = len(train_neg['Mensagem'])/len(train_all['Mensagem'])\n",
    "irrelevant_review_probability = len(train_irr['Mensagem'])/len(train_all['Mensagem'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com todas essas informações, passaremos para o processo de montar o classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador de treino\n",
    "\n",
    "Para começar a montagem do classificador, teremos que primeiramente usar as funções de limpeza para facilitar a identificação. Após, iremos montar probabilidades condicionais com base em todas as variáveis que montamos que mostram as probabilidades de cada tipo de avaliação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função básica de condicional que iremos usar é:\n",
    "\n",
    "\n",
    "$$P(Review|word_n) = P(word_n|Review)/P(word_n)$$\n",
    "\n",
    "\n",
    "Pode perceber que nessa função, está faltando a multiplicação pelo condicional de ser uma avaliação daquele tipo. Chegaremos nesse ponto ainda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterando e multiplicando uma operação dessas sobre a seguinte, de forma igual, teremos o seguinte formato de fórmula:\n",
    "\n",
    "$$P(Review|word_1,word_2,...,word_n) = P(word_1,word_2,...,word_n|Review)/P(word_1,word_2,...,word_n)$$\n",
    "\n",
    "Com isso, basta multiplicar o resultado final pelo tipo de avaliação que se deseja observar, ou seja, multiplicar por $P(Review)$.\n",
    "\n",
    "Após isso, comparamos qual é a maior probabilidade, e aquele que for maior, terá o valor atribuído à mensagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classificador_Treino(phrase) -> int:\n",
    "\n",
    "    # Começamos por limpar as mensagens.\n",
    "\n",
    "    phrase = cleanup(phrase)\n",
    "    phrase = limpaStopwords(phrase)\n",
    "    words_in_review = phrase.split()\n",
    "    prob_positive = 1\n",
    "    prob_negative = 1\n",
    "    prob_irrelevant = 1\n",
    "\n",
    "    # Então, fazemos o cálculo probabilístico mostrado acima.\n",
    "\n",
    "    for word in words_in_review:\n",
    "        if word in all_words_positive:\n",
    "            prob_positive *= word_probability_positive[word]/word_probability_total[word]\n",
    "        if word in all_words_negative:\n",
    "            prob_negative *= word_probability_negative[word]/word_probability_total[word]\n",
    "        if word in all_words_irrelevant:\n",
    "            prob_irrelevant *= word_probability_irrelevant[word]/word_probability_total[word]\n",
    "\n",
    "    prob_positive *= positive_review_probability\n",
    "    prob_negative *= negative_review_probability\n",
    "    prob_irrelevant *= irrelevant_review_probability\n",
    "\n",
    "    # Aqui, aplicamos o conceito dito no final: se o valor máximo da\n",
    "    # lista for uma avaliação positiva, retorna 1; negativa, 2; irrelevante, 0.\n",
    "\n",
    "    chances = [prob_positive,prob_negative,prob_irrelevant]\n",
    "    if prob_positive == max(chances):\n",
    "        return 1\n",
    "    if prob_negative == max(chances):\n",
    "        return 2\n",
    "    if prob_irrelevant == max(chances):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a função montada, basta então aplicar no Dataframe inteiro de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.8</td>\n",
       "      <td>14.8</td>\n",
       "      <td>47.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0      0     1     2\n",
       "Target                  \n",
       "0       20.6   0.4   0.0\n",
       "1        0.0  13.8   0.0\n",
       "2        2.8  14.8  47.6"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot_train = []\n",
    "for review in train_all['Mensagem']:\n",
    "\n",
    "    # Nessa iteração, estamos aplicando o classificador em cada mensagem do Dataframe original.\n",
    "\n",
    "    classification = Classificador_Treino(review)\n",
    "    bot_train.append(classification)\n",
    "pd.crosstab(train['Target'],bot_train,normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao comparar as classificações que o classificador montou com as verdadeiras, que são os valores na diagonal, é possível observar que a precisão no treino foi de aproximadamente 82%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Hora de colocar o classificador pelo teste de fogo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para isso, iremos repetir o mesmo processo que fizemos anteriormente, agora para o Dataframe de testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos = test.loc[test['Target'] == 1, ['Mensagem']]\n",
    "test_neg = test.loc[test['Target'] == 2, ['Mensagem']]\n",
    "test_irr = test.loc[test['Target'] == 0, ['Mensagem']]\n",
    "test_all = test.loc[:,['Mensagem']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "\n",
    "for review in test_all['Mensagem']:\n",
    "    review = cleanup(review)\n",
    "    review = limpaStopwords(review)\n",
    "    words_review = review.split()\n",
    "    for word in words_review:\n",
    "        if word not in all_words:\n",
    "            all_words.append(word)\n",
    "\n",
    "word_probability_total = {}\n",
    "\n",
    "for word in all_words:\n",
    "    count_word = 0\n",
    "    for review in test_all['Mensagem']:\n",
    "        review = cleanup(review)\n",
    "        review = limpaStopwords(review)\n",
    "        words_review = review.split()\n",
    "        if word in words_review:\n",
    "            count_word += 1\n",
    "    prob_appearance = count_word/len(test_all['Mensagem'])\n",
    "    word_probability_total[word] = prob_appearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_positive = []\n",
    "\n",
    "for review in test_pos['Mensagem']:\n",
    "    review = cleanup(review)\n",
    "    review = limpaStopwords(review)\n",
    "    words_review = review.split()\n",
    "    for word in words_review:\n",
    "        if word not in all_words_positive:\n",
    "            all_words_positive.append(word)\n",
    "\n",
    "word_probability_positive = {}\n",
    "\n",
    "for word in all_words_positive:\n",
    "    count_word = 0\n",
    "    for review in test_pos['Mensagem']:\n",
    "        review = cleanup(review)\n",
    "        review = limpaStopwords(review)\n",
    "        words_review = review.split()\n",
    "        if word in words_review:\n",
    "            count_word += 1\n",
    "    prob_appearance = count_word/len(test_pos['Mensagem'])\n",
    "    word_probability_positive[word] = prob_appearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_negative = []\n",
    "\n",
    "for review in test_neg['Mensagem']:\n",
    "    review = cleanup(review)\n",
    "    review = limpaStopwords(review)\n",
    "    words_review = review.split()\n",
    "    for word in words_review:\n",
    "        if word not in all_words_negative:\n",
    "            all_words_negative.append(word)\n",
    "\n",
    "word_probability_negative = {}\n",
    "\n",
    "for word in all_words_negative:\n",
    "    count_word = 0\n",
    "    for review in test_neg['Mensagem']:\n",
    "        review = cleanup(review)\n",
    "        review = limpaStopwords(review)\n",
    "        words_review = review.split()\n",
    "        if word in words_review:\n",
    "            count_word += 1\n",
    "    prob_appearance = count_word/len(test_neg['Mensagem'])\n",
    "    word_probability_negative[word] = prob_appearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_irrelevant = []\n",
    "\n",
    "for review in test_irr['Mensagem']:\n",
    "    review = cleanup(review)\n",
    "    review = limpaStopwords(review)\n",
    "    words_review = review.split()\n",
    "    for word in words_review:\n",
    "        if word not in all_words_irrelevant:\n",
    "            all_words_irrelevant.append(word)\n",
    "\n",
    "word_probability_irrelevant = {}\n",
    "\n",
    "for word in all_words_irrelevant:\n",
    "    count_word = 0\n",
    "    for review in test_irr['Mensagem']:\n",
    "        review = cleanup(review)\n",
    "        review = limpaStopwords(review)\n",
    "        words_review = review.split()\n",
    "        if word in words_review:\n",
    "            count_word += 1\n",
    "    prob_appearance = count_word/len(test_irr['Mensagem'])\n",
    "    word_probability_irrelevant[word] = prob_appearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_review_probability = len(test_pos['Mensagem'])/len(test_all['Mensagem'])\n",
    "negative_review_probability = len(test_neg['Mensagem'])/len(test_all['Mensagem'])\n",
    "irrelevant_review_probability = len(test_irr['Mensagem'])/len(test_all['Mensagem'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O classificador continua o mesmo, apenas renomeado para praticidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classificador_Teste(phrase) -> int:\n",
    "    phrase = cleanup(phrase)\n",
    "    phrase = limpaStopwords(phrase)\n",
    "    words_in_review = phrase.split()\n",
    "    prob_positive = 1\n",
    "    prob_negative = 1\n",
    "    prob_irrelevant = 1\n",
    "    for word in words_in_review:\n",
    "        if word in all_words_positive:\n",
    "            prob_positive *= word_probability_positive[word]/word_probability_total[word]\n",
    "        if word in all_words_negative:\n",
    "            prob_negative *= word_probability_negative[word]/word_probability_total[word]\n",
    "        if word in all_words_irrelevant:\n",
    "            prob_irrelevant *= word_probability_irrelevant[word]/word_probability_total[word]\n",
    "\n",
    "    prob_positive *= positive_review_probability\n",
    "    prob_negative *= negative_review_probability\n",
    "    prob_irrelevant *= irrelevant_review_probability\n",
    "\n",
    "    chances = [prob_positive,prob_negative,prob_irrelevant]\n",
    "    if prob_positive == max(chances):\n",
    "        return 1\n",
    "    if prob_negative == max(chances):\n",
    "        return 2\n",
    "    if prob_irrelevant == max(chances):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>53.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0      0     1     2\n",
       "Target                  \n",
       "0       18.0   0.8   0.0\n",
       "1        0.0   3.6   0.0\n",
       "2        4.0  20.4  53.2"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot_test = []\n",
    "for review in test_all['Mensagem']:\n",
    "    classification = Classificador_Treino(review)\n",
    "    bot_test.append(classification)\n",
    "pd.crosstab(test['Target'],bot_test,normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isso, verificamos que o nosso classificador teve uma precisão de 74,6% no Dataframe de testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em conclusão, o classificador é bastante efetivo, com uma precisão bastante alta. Porém, há uma breve ideia sobre o que acontece para que o classificador não chegue em mais de 90%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grande parte das avaliações possui um tom de ironia em diversos aspectos. Portanto, mesmo que as palavras sejam um bom indicativo, é bastante difícil (para não dizer impossível) que seja levada em consideração também a construção da mensagem e a intenção original do autor dela."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outro aspecto é a falta do método de Suavização de LaPlace. Por conta da forma que o código foi implementado, a suavização se tornou um processo que dificultaria não apenas o desenvolvimento, mas também o entendimento geral do projeto, quando observado nosso conhecimento atual. O método de suavização seria especialmente útil para distribuir melhor as probabilidades e evitar casos zero (onde uma probabilidade é zero), visto que sua fórmula é:\n",
    "\n",
    "$$P'(A|B) = (Número\\;de\\;casos + 1)/(Número\\;de\\;exemplos\\;totais\\;do\\;caso + Exemplos\\;de\\;casos\\;virtuais)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas, no geral, o classificador foi bastante preciso em sua classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método Naive Bayes e o classificador montado podem ser utilizados, além das avaliações, para compreender alguns crescimentos gráficos e, aplicando ao mundo real, em possibilidades meteorológicas em certas regiões, como visto em uma apresentação da Universidade Federal do Paraná sobre estatística e probabilidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CONSIDEROU mais de duas categorias na variável Target e INCREMENTOU a quantidade de notícias, mantendo pelo menos 250 notícias por categoria (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* Para Target com duas categorias: CRIOU pelo menos quatro categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto (pelo menos dois cenários, exceto aqueles já apresentados em sala pelos professores: por exemplo, filtro de spam)\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item Qualidade do Classificador a partir de novas separações das Notícias entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**\n",
    "\n",
    "[Aprendizagem Bayesiana](https://www.inf.ufpr.br/menotti/ci171-182/slides/ci171-bayes.pdf) **Para compreender suavização e alguns cálculos**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
